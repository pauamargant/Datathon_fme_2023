{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidgallardo/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/davidgallardo/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.classifier = vgg16.classifier[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Resize while maintaining the original aspect ratio\n",
    "    aspect_ratio = image.width / image.height\n",
    "    if aspect_ratio > 1:\n",
    "        target_size = (int(224 * aspect_ratio), 224)\n",
    "    else:\n",
    "        target_size = (224, int(224 / aspect_ratio))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    input_image = transform(image).unsqueeze(0)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image = load_and_preprocess_image('images/2019_41005828_05.jpg')\n",
    "preprocessed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings off pandas\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9248/9248 [14:05<00:00, 10.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the images in the folder\n",
    "\n",
    "image_features = pd.DataFrame()\n",
    "count = 0\n",
    "dict = {}\n",
    "for filename in tqdm.tqdm(os.listdir(images_folder)):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "\n",
    "        count += 1\n",
    "    \n",
    "        # Load and preprocess the image\n",
    "        image_path = os.path.join(images_folder, filename)\n",
    "        input_image = load_and_preprocess_image(image_path)\n",
    "\n",
    "        # Make predictions using the VGG16 model\n",
    "        with torch.no_grad():\n",
    "            output = vgg16(input_image)\n",
    "\n",
    "\n",
    "        output = torch.nn.functional.normalize(output, p=2, dim=1)\n",
    "\n",
    "        tensor_values = output.view(-1).tolist()\n",
    "\n",
    "        # Create a dictionary containing the image filename and the tensor values\n",
    "        dict[filename] = tensor_values\n",
    "\n",
    "        # Append the dictionary to the image_features DataFrame, use concat\n",
    "\n",
    "\n",
    "\n",
    "        #image_features = pd.concat([image_features, pd.DataFrame({'filename': filename, 'tensor_values': tensor_values})], ignore_index=True)\n",
    "        \n",
    "\n",
    "\n",
    "        # Print the top prediction\n",
    "        #_, predicted_class = torch.max(output, 1)\n",
    "\n",
    "        # Map the predicted class index to the label using the loaded JSON file\n",
    "        #predicted_label = class_labels[predicted_class.item()]\n",
    "\n",
    "        # Print the results\n",
    "        #print(f\"Image: {filename}, Predicted Class: {predicted_label} (Class Index: {predicted_class.item()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'Filename': filename, **{f'Weight_{i+1}': weight for i, weight in enumerate(weights)}}\n",
    "        for filename, weights in dict.items()]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Weight_1</th>\n",
       "      <th>Weight_2</th>\n",
       "      <th>Weight_3</th>\n",
       "      <th>Weight_4</th>\n",
       "      <th>Weight_5</th>\n",
       "      <th>Weight_6</th>\n",
       "      <th>Weight_7</th>\n",
       "      <th>Weight_8</th>\n",
       "      <th>Weight_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight_4087</th>\n",
       "      <th>Weight_4088</th>\n",
       "      <th>Weight_4089</th>\n",
       "      <th>Weight_4090</th>\n",
       "      <th>Weight_4091</th>\n",
       "      <th>Weight_4092</th>\n",
       "      <th>Weight_4093</th>\n",
       "      <th>Weight_4094</th>\n",
       "      <th>Weight_4095</th>\n",
       "      <th>Weight_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023_57045979_TO.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023_57007758_92.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023_57077728_76.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038184</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023_57043798_99.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019_57017881_37.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename  Weight_1  Weight_2  Weight_3  Weight_4  Weight_5  \\\n",
       "0  2023_57045979_TO.jpg       0.0       0.0  0.000000       0.0       0.0   \n",
       "1  2023_57007758_92.jpg       0.0       0.0  0.000000       0.0       0.0   \n",
       "2  2023_57077728_76.jpg       0.0       0.0  0.009204       0.0       0.0   \n",
       "3  2023_57043798_99.jpg       0.0       0.0  0.000000       0.0       0.0   \n",
       "4  2019_57017881_37.jpg       0.0       0.0  0.000000       0.0       0.0   \n",
       "\n",
       "   Weight_6  Weight_7  Weight_8  Weight_9  ...  Weight_4087  Weight_4088  \\\n",
       "0  0.000000  0.000000  0.001199       0.0  ...     0.035152          0.0   \n",
       "1  0.000000  0.000000  0.000000       0.0  ...     0.028601          0.0   \n",
       "2  0.013492  0.000000  0.000000       0.0  ...     0.005700          0.0   \n",
       "3  0.000000  0.000000  0.000000       0.0  ...     0.070853          0.0   \n",
       "4  0.000000  0.006811  0.000942       0.0  ...     0.000000          0.0   \n",
       "\n",
       "   Weight_4089  Weight_4090  Weight_4091  Weight_4092  Weight_4093  \\\n",
       "0          0.0          0.0     0.000000     0.008423     0.052571   \n",
       "1          0.0          0.0     0.000000     0.000000     0.033525   \n",
       "2          0.0          0.0     0.000000     0.038184     0.022136   \n",
       "3          0.0          0.0     0.000000     0.000000     0.000000   \n",
       "4          0.0          0.0     0.007957     0.000000     0.015474   \n",
       "\n",
       "   Weight_4094  Weight_4095  Weight_4096  \n",
       "0          0.0     0.000000          0.0  \n",
       "1          0.0     0.000000          0.0  \n",
       "2          0.0     0.000000          0.0  \n",
       "3          0.0     0.018857          0.0  \n",
       "4          0.0     0.000000          0.0  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9248, 4097)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to a picle\n",
    "df.to_pickle('image_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the df to json\n",
    "df.to_json('image_features.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
